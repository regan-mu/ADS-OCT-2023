{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfeb85a1",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26ff0c81",
   "metadata": {},
   "source": [
    "## Table of content \n",
    "\n",
    "### 1 Introduction to Classification\n",
    "\n",
    "* What is classification?\n",
    "* Types of classification problems\n",
    "* Real-world examples of classification tasks\n",
    "\n",
    "### 2 Getting Started with scikit-learn\n",
    "* Loading datasets and preprocessing\n",
    "\n",
    "### 3 Supervised Learning: Classification Techniques\n",
    "\n",
    "* a. Logistic Regression\n",
    "* b. K-Nearest Neighbors (KNN)\n",
    "* c. Support Vector Machines (SVM)\n",
    "* d. Decision Trees\n",
    "* e. Random Forest\n",
    "\n",
    "### 4 Model Evaluation and Selection\n",
    "\n",
    "* Train-test split\n",
    "* Cross-validation\n",
    "* Performance metrics (accuracy, precision, recall, F1-score, ROC-AUC)\n",
    "* Hyperparameter tuning (Grid search, Random search)\n",
    "* Model selection and comparison\n",
    "\n",
    "### 5 Advanced Classification Techniques\n",
    "* a. Imbalanced Classification\n",
    "\n",
    "### 6  Practical Project\n",
    "\n",
    "* Choosing a classification dataset\n",
    "* Data preprocessing and exploration\n",
    "* Model selection, training, and evaluation\n",
    "* Hyperparameter tuning and model optimization\n",
    "* Presenting the final results  \n",
    "\n",
    "### 7 Assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f05994f",
   "metadata": {},
   "source": [
    "## 1 Introduction to Classification\n",
    "\n",
    "### What is classification?\n",
    "\n",
    "Classification is a type of supervised machine learning task in which the goal is to assign objects or instances to predefined categories or classes. In supervised learning, the model learns from a dataset that contains input-output pairs, where the output (or target) is a discrete value representing the class label. Classification models can be used to predict the class of an object based on its input features.\n",
    "\n",
    "### Types of classification problems:\n",
    "\n",
    "There are two main types of classification problems:\n",
    "    \n",
    "    \n",
    "\n",
    "* a. Binary Classification: In binary classification, there are only two possible classes. The model is trained to distinguish between these two classes. For example, classifying emails as spam or not spam.\n",
    "\n",
    "* b. Multiclass Classification: In multiclass classification, there are more than two possible classes. The model is trained to classify instances into one of the multiple classes. For example, classifying handwritten digits into one of the ten classes (0 to 9)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0efb6445",
   "metadata": {},
   "source": [
    "In some cases, you might also encounter multilabel classification problems, where each instance can be assigned to multiple classes simultaneously. For example, classifying a text document into multiple topics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23d767a8",
   "metadata": {},
   "source": [
    "### Real-world examples of classification tasks:\n",
    "\n",
    "\n",
    "Here are some real-world examples of classification tasks:\n",
    "\n",
    "* a. Email spam detection: Identifying whether an email is spam or not based on its content and other features.\n",
    "\n",
    "* b. Medical diagnosis: Predicting the presence or absence of a disease based on patient data (e.g., symptoms, lab results).\n",
    "\n",
    "* c. Sentiment analysis: Determining the sentiment (positive, negative, or neutral) of a given text or document.\n",
    "\n",
    "* d. Handwritten digit recognition: Identifying the digit (0 to 9) represented by a handwritten image.\n",
    "\n",
    "* e. Fraud detection: Detecting fraudulent transactions in a financial dataset based on transaction data and user behavior.\n",
    "\n",
    "* f. Image classification: Categorizing images into predefined classes, such as animals, objects, or scenes.\n",
    "\n",
    "* g. Customer segmentation: Classifying customers into groups based on their behavior or preferences for targeted marketing.\n",
    "\n",
    "These are just a few examples; classification problems are widespread across various domains and industries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b825ff93",
   "metadata": {},
   "source": [
    "## 2 Getting Started with scikit-learn\n",
    "\n",
    "Scikit-learn is a popular Python library for machine learning that provides simple and efficient tools for data mining and data analysis. To install scikit-learn, you can use the following command with pip:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fc5c7d3",
   "metadata": {},
   "source": [
    "### Loading datasets and preprocessing:\n",
    "\n",
    "Scikit-learn provides various utilities for loading datasets and preprocessing the data. Some common tasks include:\n",
    "\n",
    "* a. **Loading datasets**: Scikit-learn comes with several built-in datasets (e.g., iris, digits, breast cancer) that can be loaded using the datasets module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "#iris.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00bf75ac",
   "metadata": {},
   "source": [
    "* b. **Data splitting**: Split the data into training and testing sets using the train_test_split function from the model_selection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a08a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42, stratify=iris.target)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97625ec8",
   "metadata": {},
   "source": [
    "* c. **Feature scaling:** Standardize or normalize the data using transformers like StandardScaler or MinMaxScaler from the preprocessing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2bbda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f3db1ae",
   "metadata": {},
   "source": [
    "* **Handling missing values** : Impute missing values using transformers like SimpleImputer from the impute module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a092f069",
   "metadata": {},
   "source": [
    "By understanding the scikit-learn API and its utilities, you can load, preprocess, and prepare your data for various classification tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4eb6897b",
   "metadata": {},
   "source": [
    "# 3 Supervised Learning: Classification Techniques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc3676c4",
   "metadata": {},
   "source": [
    "### a. Logistic Regression\n",
    "\n",
    "#### Understanding logistic regression: \n",
    "\n",
    "Logistic regression is a linear model used for binary classification tasks. It estimates the probability of an instance belonging to a class using the logistic function (sigmoid function). The model is trained to find the best-fitting decision boundary that separates the two classes.\n",
    "\n",
    "#### Implementing logistic regression with scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "predictions = logreg.predict(X_test_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8db6bb5",
   "metadata": {},
   "source": [
    "### b. K-Nearest Neighbors (KNN)\n",
    "\n",
    "#### Understanding KNN: \n",
    "\n",
    "K-Nearest Neighbors is a non-parametric, instance-based learning algorithm used for classification tasks. Given a new instance, KNN finds the k nearest training instances in the feature space and assigns the majority class label among these neighbors.\n",
    "\n",
    "#### Implementing KNN with scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac247c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "predictions = knn.predict(X_test_scaled)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "900b3b7d",
   "metadata": {},
   "source": [
    "### c. Support Vector Machines (SVM)\n",
    "\n",
    "#### Understanding SVM:\n",
    "Support Vector Machines is a powerful classification algorithm that can be used for linear or non-linear classification tasks. The main idea of SVM is to find the hyperplane that best separates the classes with the maximum margin, which is the distance between the hyperplane and the nearest instances from each class (support vectors).\n",
    "\n",
    "#### Implementing SVM with scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "predictions = svm.predict(X_test_scaled)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd83a816",
   "metadata": {},
   "source": [
    "### d. Decision Trees\n",
    "\n",
    "#### Understanding decision trees: \n",
    "Decision trees are a type of flowchart-like structure used for classification tasks. The tree consists of nodes, which represent features or decisions, and branches, which represent the outcome of a decision. The model is trained to recursively split the data based on the feature that provides the best separation of the classes.\n",
    "\n",
    "#### Implementing decision trees with scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f10d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dtree.fit(X_train_scaled, y_train)\n",
    "predictions = dtree.predict(X_test_scaled)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28d0694f",
   "metadata": {},
   "source": [
    "### e. Random Forest\n",
    "\n",
    "#### Understanding random forest: \n",
    "\n",
    "Random Forest is an ensemble learning method that constructs multiple decision trees and combines their predictions through majority voting. It improves the performance and generalization of a single decision tree by reducing overfitting and adding randomness to the model.\n",
    "\n",
    "#### Implementing random forest with scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07fd01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "predictions = rf.predict(X_test_scaled)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54be9a21",
   "metadata": {},
   "source": [
    "## 4 Model Evaluation and Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e3d7c51",
   "metadata": {},
   "source": [
    "### Train-test split:\n",
    "The train-test split is a technique used to divide the dataset into two parts, one for training the model and the other for testing the model's performance. This helps to evaluate the model's ability to generalize to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25766dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96a57afd",
   "metadata": {},
   "source": [
    "### Cross-validation:\n",
    "Cross-validation is a more robust technique for evaluating the model's performance by dividing the dataset into multiple folds. The model is trained and tested multiple times, using different combinations of training and testing folds. The most common method is k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d82f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X, y, cv=5)  # 5-fold cross-validation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9dc7893d",
   "metadata": {},
   "source": [
    "### Performance metrics:\n",
    "\n",
    "Various performance metrics can be used to evaluate the quality of a classification model. Some common metrics include:\n",
    "\n",
    "* **Accuracy**: The proportion of correct predictions among the total number of instances.\n",
    "* **Precision**: The proportion of true positives among the instances predicted as positive.\n",
    "* **Recall (Sensitivity)**: The proportion of true positives among the instances that are actually positive.\n",
    "* **F1-score:** The harmonic mean of precision and recall.\n",
    "* **ROC-AUC:** The area under the receiver operating characteristic (ROC) curve, which plots the true positive rate against the false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a849f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "roc_auc = roc_auc_score(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39f552dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00        15\\n           1       0.82      0.93      0.87        15\\n           2       0.92      0.80      0.86        15\\n\\n    accuracy                           0.91        45\\n   macro avg       0.92      0.91      0.91        45\\nweighted avg       0.92      0.91      0.91        45\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(y_test, predictions)\n",
    "report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91185506",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning:\n",
    "\n",
    "Hyperparameter tuning is the process of finding the optimal values for the hyperparameters of a model. Two popular methods for hyperparameter tuning are grid search and random search.\n",
    "\n",
    "#### Grid search: \n",
    "Exhaustively tries all possible combinations of hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e176eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17b579c0",
   "metadata": {},
   "source": [
    "#### Random search: \n",
    "\n",
    "Samples a random combination of hyperparameter values within specified ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48003e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "random_search = RandomizedSearchCV(SVC(), param_dist, n_iter=10, cv=5)\n",
    "random_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb5edcc8",
   "metadata": {},
   "source": [
    "### Model selection and comparison:\n",
    "\n",
    "After evaluating the performance of different models and tuning their hyperparameters, you can compare the models and select the one that performs best on the chosen metrics. This will help you choose the most suitable model for your classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab762d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Comparing the accuracy of two models\n",
    "accuracy_logreg = accuracy_score(y_test, predictions_logreg)\n",
    "accuracy_knn = accuracy_score(y_test, predictions_knn)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_logreg)\n",
    "print(\"K-Nearest Neighbors Accuracy:\", accuracy_knn)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42c89f4c",
   "metadata": {},
   "source": [
    "### 5 Advanced Classification Techniques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8d587b6",
   "metadata": {},
   "source": [
    "### Imbalanced Classification\n",
    "Imbalanced classification deals with datasets where one class is significantly under-represented compared to the other classes. This can lead to biased models that perform poorly on the minority class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bee03aa6",
   "metadata": {},
   "source": [
    "#### Understanding imbalanced datasets: \n",
    "\n",
    "Imbalanced datasets can occur in real-world problems like fraud detection, medical diagnosis, and rare event prediction. The imbalance can lead to a higher misclassification rate for the minority class, as the model is biased towards the majority class.\n",
    "\n",
    "#### Resampling techniques: \n",
    "\n",
    "Resampling techniques can be used to balance the class distribution by either oversampling the minority class or undersampling the majority class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "992165f6",
   "metadata": {},
   "source": [
    "* **Oversampling**: Randomly replicating instances from the minority class to increase its representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy='minority')\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "303aa3d6",
   "metadata": {},
   "source": [
    "* **Undersampling**: Randomly removing instances from the majority class to decrease its representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec102c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9786977d",
   "metadata": {},
   "source": [
    "#### Evaluation metrics for imbalanced datasets: \n",
    "\n",
    "In imbalanced datasets, accuracy is not a suitable metric, as it can be misleading due to the bias towards the majority class. Instead, other metrics like precision, recall, F1-score, and the area under the precision-recall curve (PR-AUC) should be used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa0a9f19",
   "metadata": {},
   "source": [
    "Precision-Recall Curve and PR-AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412c259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "pr_auc = auc(recall, precision)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f30f63a",
   "metadata": {},
   "source": [
    "By using advanced classification techniques like ensemble methods and addressing imbalanced datasets with resampling techniques, you can improve the performance and generalization of your classification models. Additionally, using appropriate evaluation metrics will help you better assess and compare models on imbalanced datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3e126cb",
   "metadata": {},
   "source": [
    "## 6 Practical Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21fb76f3",
   "metadata": {},
   "source": [
    "In this practical project, we will go through the process of choosing a real-world classification dataset, preprocessing and exploring the data, selecting, training, and evaluating models, tuning hyperparameters, and presenting the final results.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24e129b9",
   "metadata": {},
   "source": [
    "### 1 Choosing a classification dataset:\n",
    "Find a suitable classification dataset for your project. Examples include the Iris dataset, the Breast Cancer Wisconsin dataset, or the Wine Quality dataset. You can also explore public datasets available on platforms like Kaggle or UCI Machine Learning Repository.\n",
    "\n",
    "### 2 Data preprocessing and exploration:\n",
    "Load the dataset, clean the data if necessary, and perform exploratory data analysis to understand the data's characteristics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c84fa1f",
   "metadata": {},
   "source": [
    "In this example, I'll use the Wine Quality dataset from the UCI Machine Learning Repository. Here's the code to load the data and perform exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Basic statistics\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Visualize feature distributions and relationships\n",
    "sns.pairplot(data, hue='quality', corner=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa68d586",
   "metadata": {},
   "source": [
    "### 3 Model selection, training, and evaluation:\n",
    "\n",
    "Split the data into training and testing sets, train different classification models, and evaluate their performance using appropriate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e14197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Preprocessing\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Training and evaluating models\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_preds = logreg.predict(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "svc_preds = svc.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "def evaluate(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "logreg_metrics = evaluate(y_test, logreg_preds)\n",
    "rf_metrics = evaluate(y_test, rf_preds)\n",
    "svc_metrics = evaluate(y_test, svc_preds)\n",
    "\n",
    "print(\"Logistic Regression Metrics - Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(*logreg_metrics))\n",
    "print(\"Random Forest Metrics - Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(*rf_metrics))\n",
    "print(\"SVM Metrics - Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(*svc_metrics))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c671b275",
   "metadata": {},
   "source": [
    "This code loads the Wine Quality dataset, preprocesses it, splits it into training and testing sets, trains three classification models, and evaluates their performance using accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "246abbcc",
   "metadata": {},
   "source": [
    "### 4 Hyperparameter tuning and model optimization:\n",
    "    \n",
    "Optimize the models' performance by tuning their hyperparameters using techniques like grid search or random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Preprocessing\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Training and evaluating the baseline model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "def evaluate(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "rf_metrics = evaluate(y_test, rf_preds)\n",
    "print(\"Baseline Random Forest Metrics - Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(*rf_metrics))\n",
    "\n",
    "# Hyperparameter tuning using Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Training and evaluating the optimized model\n",
    "rf_optimized = RandomForestClassifier(**best_params)\n",
    "rf_optimized.fit(X_train, y_train)\n",
    "rf_optimized_preds = rf_optimized.predict(X_test)\n",
    "\n",
    "rf_optimized_metrics = evaluate(y_test, rf_optimized_preds)\n",
    "print(\"Optimized Random Forest Metrics - Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(*rf_optimized_metrics))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92b4af1f",
   "metadata": {},
   "source": [
    "This code loads the Wine Quality dataset, preprocesses it, splits it into training and testing sets, trains a baseline Random Forest model, and evaluates its performance. Then, it performs hyperparameter tuning using Grid Search and retrains the optimized model, evaluating its performance to compare with the baseline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6280de7f",
   "metadata": {},
   "source": [
    "### 5 Presenting the final results:\n",
    "After optimizing the models, select the best model based on the chosen evaluation metrics, and present the final results, including the model's performance on the test dataset, feature importances or coefficients, and any insights derived from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b662c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Preprocessing\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter tuning using Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Training and evaluating the optimized model\n",
    "rf_optimized = RandomForestClassifier(**best_params)\n",
    "rf_optimized.fit(X_train, y_train)\n",
    "rf_optimized_preds = rf_optimized.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "def evaluate(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "rf_optimized_metrics = evaluate(y_test, rf_optimized_preds)\n",
    "print(\"Optimized Random Forest Metrics - Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(*rf_optimized_metrics))\n",
    "\n",
    "# Identifying important features\n",
    "important_features = pd.Series(rf_optimized.feature_importances_, index=X.columns)\n",
    "important_features = important_features.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nImportant Features:\")\n",
    "print(important_features)\n",
    "\n",
    "# Conclusion\n",
    "print(\"\\nBased on the evaluation metrics, the Optimized Random Forest model is the best-performing model.\")\n",
    "print(\"The top features contributing to wine quality prediction are:\")\n",
    "print(important_features.head(5))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f41a97fb",
   "metadata": {},
   "source": [
    "This code loads the Wine Quality dataset, preprocesses it, splits it into training and testing sets, performs hyperparameter tuning using Grid Search, and trains the optimized Random Forest model. It then evaluates the model's performance on the test dataset, identifies the important features, and presents the final results.\n",
    "\n",
    "In the conclusion, we report the best model based on the chosen evaluation metrics and list the top features contributing to wine quality prediction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b6e11e4",
   "metadata": {},
   "source": [
    "## 8 Assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29cd3227",
   "metadata": {},
   "source": [
    "## Assignment: Predicting Customer Churn\n",
    "\n",
    "### Objective: \n",
    "\n",
    "The goal of this assignment is to build a classification model to predict whether a customer will churn (stop using a service) based on their features and interactions with the service.\n",
    "\n",
    "### Dataset: \n",
    "The Telco Customer Churn dataset, available on Kaggle, contains information about a fictional telecommunication company's customers and whether they have churned. You can download the dataset here.\n",
    " https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
    "\n",
    "### Tasks:\n",
    "\n",
    "* Load and explore the dataset: Analyze the distribution of features, check for missing values, and visualize relationships between features and the target variable (churn).\n",
    "\n",
    "    \n",
    "    \n",
    "* Preprocess the data: Handle missing values, convert categorical variables to numeric, and normalize/standardize the features if necessary.\n",
    "\n",
    "    \n",
    "    \n",
    "* Split the dataset: Divide the dataset into training and testing sets.\n",
    "\n",
    "    \n",
    "    \n",
    "* Train classification models: Train various classification models (e.g., logistic regression, KNN, SVM, decision tree, random forest, etc.) on the training dataset.\n",
    "\n",
    "    \n",
    "    \n",
    "* Evaluate the models: Assess the performance of the models using appropriate metrics such as accuracy, precision, recall, F1-score, and ROC-AUC.\n",
    "\n",
    "    \n",
    "    \n",
    "* Optimize the models: Perform hyperparameter tuning using techniques like grid search or random search to improve the performance of the models.\n",
    "\n",
    "    \n",
    "    \n",
    "* Feature selection and dimensionality reduction: Apply feature selection techniques such as RFE, variance threshold, or dimensionality reduction methods like PCA and LDA to reduce the number of features and potentially improve model performance.\n",
    "\n",
    "    \n",
    "    \n",
    "* Select the best model: Choose the best-performing model based on the evaluation metrics.\n",
    "\n",
    "    \n",
    "    \n",
    "* Interpret the results: Discuss the performance of the chosen model, the importance of different features, and any insights gained from the analysis.\n",
    "\n",
    "    \n",
    "    \n",
    "* Conclusion: Summarize the findings, mention any limitations of the project, and suggest possible improvements or future work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a62b5782",
   "metadata": {},
   "source": [
    "# solution for the Customer Churn assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb33b6ea",
   "metadata": {},
   "source": [
    "This code provides a compact solution to the Customer Churn assignment. It loads the data, preprocesses it, trains different models, optimizes the hyperparameters, selects the most important features, and presents the results.\n",
    "\n",
    "Remember that in a real-world scenario, it's crucial to explore the data and models in more detail and interpret the results accordingly. Additionally, it is recommended to try other advanced classification techniques or address class imbalance issues if applicable to your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1d735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
